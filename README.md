<img width="1171" height="2021" alt="image" src="https://github.com/user-attachments/assets/5efdcfe2-800f-499f-8894-f617c7c60d98" />

This is the most important model created. Like the other models, it’s composed of 4 sequential processes : Pre-Processing, Train/Test set, Training, Evaluation.
The operations prior to training are performed using Spark, while the training and evaluation are carried out using the CUDA library (GPU).
--------------------
1) Pre-Processing: This stage consists of a set of operations on the dataset aimed at creating the features for the model. As a first step, new features are generated by combining existing variables (e.g., average speed on urban roads, percentage of braking events on motorways, etc.). Afterwards, all variables are normalized using Gaussian normalization.
Gaussian normalization (or z-score normalization) is a scaling technique that transforms data so that it follows a standard normal distribution with mean 0 and standard deviation 1. Each value is rescaled by subtracting the dataset’s mean and dividing by its standard deviation, allowing variables with different scales to be compared consistently : 
 	μ = Dataset mean
	σ = Dataset standard deviation
Gaussian normalization is used in ML models to ensure that features with different scales contribute equally, improve convergence during training, and enhance model stability and performance.
Finally, rows containing null values in the main columns are dropped from the dataset, while secondary columns are filled with “0”. As the final step, the variables CardC, CardD, and RCA are merged into a single column, with their values aggregated. This new column serves as the label function.
--------------------
2) Train/Test set: This stage consists of splitting the dataset into two subsets: one used for training and the other for testing (or validation), which serves to evaluate the ML model on previously unseen data.
This stage is important because the sizes of the training and test sets have a strong influence on model quality (as will be discussed later). 
The first step is to create the training set by selecting a balanced number of random records. The best solution found was 15,000 records, with half of the dataset having label = 0 and the other half label = 1.
The difference between this subset and the original dataset is then taken to ensure that these records cannot appear in the test set. At this point, another balanced random selection is performed
on the remaining dataset to create the test set. Finally, both the training and test sets are split into the domain set (X) and the label set (y), and all series and datasets are returned.
---------------------
3) Training: Before training, it is important to present the model architecture. The model is a deep learning network composed of four layers and a residual block (skip connection).
Each layer or block contains fully connected nodes, with the number of nodes halving in each subsequent block. The first block connects 32 input nodes to 512 fully connected nodes.
After the fully connected nodes, each block applies Batch Normalization to improve training stability, re-center the values around zero, and mitigate the problem of internal covariate shift.
After the normalization, every layer uses the same non-linear activation function : GELU
GELU stands for Gaussian Error Linear Unit. It’s a smooth, differentiable activation function in deep learning that weights inputs by their probability under a standard normal distribution. It’s a smoother alternative to RELU.
The last step of each layer is the Dropout. It’s a regularization technique where, during training, a random subset of neurons is temporarily deactivated. This prevents co-adaptation of neurons and helps reduce overfitting, improving the model’s generalization ability. As the number of nodes, also the Dropout intensity is halved in each subsequent block (starting from 0.4).
In parallel to the last layer, it’s present also the Residual Block. It’s a neural network block (having the structure equals to the other blocks) that introduces a skip connection, allowing the input to bypass more layers.
This helps mitigate the vanishing gradient problem. Instead of learning a mapping function H(x) from input to output, it learns a Residual Function [ F(x) = H(x) – x ], so that the output of the block became : [ y = F(X) + x ].
The “+ x” element allows the backpropagation on the layers even when F’(x) = 0
When the training starts, the .parquet file is converted in a pandas dataframe and the new dataframe is moved from the RAM into the GPU. 
The Loss function used is the BCEWithLogitsLoss : It stands for Binary Cross-Entropy with Logits Loss and it’s a loss function that combines a sigmoid activation with binary cross-entropy in a single, numerically stable operation.
It fits perfectly with binary classification tasks, where the model predicts a probability between 0 and 1. By integrating the sigmoid internally, it avoids numerical instability issues that may arise when applying sigmoid and cross-entropy separately, leading to more reliable training.
The Optimizer used is AdamW : It stands for Adaptive Moment Estimation with Weight Decay and it’s an optimizer that improves upon Adam by decoupling weight decay from the gradient-based update.
It combines the benefits of adaptive learning rates (using moving averages of gradients and squared gradients) with a more principled L2 regularization. This helps prevent weights from growing too large and generally improves generalization.
During training, the loss value at each epoch is stored in an array, which is later used to plot the loss trend using Matplotlib and save it as an external figure. 
After training is completed, the model is re-evaluated on the training dataset to measure its performance. These results are then compared with the evaluation on the test dataset in order to assess if the model is overfitting or underfitting.
------------------
4) Evaluation : This is the last step, where the model is tested using examples never seen. This model must solve a binary classification problem so the performance can be measured by using the Confusion Matrix.
It compares the predicted labels with the actual labels, organizing the results into four categories: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). This structure provides a detailed view of how the model performs across different classes, highlighting not only overall accuracy but also the types of errors made, which is particularly useful in imbalanced classification problems.
The evaluation results is saved in an external folder (.txt file).

The model hyperparameters and training parameters were chosen following a heuristic approach.
As a first step, multiple tests were conducted by varying the model architecture, and the current hyperparameters were selected as those that performed best.
Next, a series of tests were carried out using the chosen model while varying the training parameters, including the number of epochs, loss functions, optimizer, and regularization techniques.
Finally, additional tests were performed by changing the sizes of the training and test sets : A major challenge with this dataset is the underrepresentation of the positive class: less than 5% of the labels have a value of 1. Consequently, the model tends to predict 0 in order to minimize the loss function. For this reason, it is crucial to use a balanced training dataset
The dataset consists of 7,550 examples with label = 1, while the remaining examples have label = 0. When more than 15,000 examples are used, the proportion of label “1” in the training and test sets decreases, which can lead the model to overfit.
Using 15,000 examples in the training dataset was found to be the optimal solution. Additional tests were conducted by adjusting other parameters, and the best performance on the test set—while maintaining consistent results on the training set—was achieved by reducing the number of epochs from 1,750 to 1,500.
---------------
The current model predicted 82% of the claims in the Training set and 81% of the claims in the Test set.

Training set evaluation (Confusion Matrix and its metrics): 
<img width="1443" height="721" alt="image" src="https://github.com/user-attachments/assets/faf8710f-a6ee-46ac-8de5-99e045a4bed1" />

Test set evaluation :
<img width="433" height="205" alt="image" src="https://github.com/user-attachments/assets/a1fb8450-6cdf-417d-9955-c61d5f3e5d8d" />

Loss curve during the training : 
<img width="640" height="480" alt="image" src="https://github.com/user-attachments/assets/bbe7c46a-ac9b-46a1-90f8-f6ac4fed38c4" />
